<!doctype html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport"
          content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <title>Hello WebXR!</title>

    <!-- three.js -->
    <script src="https://unpkg.com/three@0.126.0/build/three.js"></script>
    <script src="https://unpkg.com/three@0.126.0/examples/js/loaders/GLTFLoader.js"></script>
</head>
<body>
<button onclick="activateXR()">Start Hello WebXR</button>
<script>

    async function activateXR() {
        // Add a canvas element and initialize a WebGL context that is compatible with WebXR.
        const canvas = document.createElement("canvas");
        document.body.appendChild(canvas);
        const gl = canvas.getContext("webgl", {xrCompatible: true});

        // To be continued in upcoming steps.

        const scene = new THREE.Scene();

        const directionalLight = new THREE.DirectionalLight(0xffffff, 0.3);
        directionalLight.position.set(10, 15, 10);
        scene.add(directionalLight);

        // Set up the WebGLRenderer, which handles rendering to the session's base layer.
        const renderer = new THREE.WebGLRenderer({
            alpha: true,
            preserveDrawingBuffer: true,
            canvas: canvas,
            context: gl
        });
        renderer.autoClear = false;

        // The API directly updates the camera matrices.
        // Disable matrix auto updates so three.js doesn't attempt
        // to handle the matrices independently.
        const camera = new THREE.PerspectiveCamera();
        camera.matrixAutoUpdate = false;
        // Initialize a WebXR session using "immersive-ar".
        const session = await navigator.xr.requestSession("immersive-ar", {requiredFeatures: ['hit-test']});
        session.updateRenderState({
            baseLayer: new XRWebGLLayer(session, gl)
        });

        // A 'local' reference space has a native origin that is located
        // near the viewer's position at the time the session was created.
        const referenceSpace = await session.requestReferenceSpace('local');

        // Texture Loader for images
        const textureLoader = new THREE.TextureLoader();

        // Image Viewer (initially invisible)
        const imageViewSize = 2; // You can adjust this as needed
        const imageMaterial = new THREE.MeshBasicMaterial({ transparent: true, opacity: 0 });
        const imageView = new THREE.Mesh(new THREE.PlaneGeometry(imageViewSize, imageViewSize), imageMaterial);
        imageView.position.set(0, 0, -2); // Adjust the position to ensure visibility
        scene.add(imageView);

        // Create buttons
        const buttonSize = .5;
        const buttonMaterial = new THREE.MeshBasicMaterial({color: 0x000000});
        const rotationY = THREE.MathUtils.degToRad(90);

        const githubButton = new THREE.Mesh(new THREE.BoxGeometry(buttonSize, buttonSize, 0.2), new THREE.MeshBasicMaterial({color: 0x000000}));
        githubButton.position.set(0, 0, -1);  // Start from the topmost button
        githubButton.rotation.y = rotationY;
        githubButton.userData = { type: 'link', url: 'https://github.com/ConnerC0' };
        scene.add(githubButton);

        const linkedinButton = new THREE.Mesh(new THREE.BoxGeometry(buttonSize, buttonSize, 0.2), new THREE.MeshBasicMaterial({color: 0x00FFFF}));
        linkedinButton.position.set(1.5, 0, -1);  // Move down by buttonSpacing
        linkedinButton.rotation.y = rotationY;
        linkedinButton.userData.url = 'https://www.linkedin.com/in/conner-curtis/';
        scene.add(linkedinButton);

        const contactButton = new THREE.Mesh(new THREE.BoxGeometry(buttonSize, buttonSize, 0.2), new THREE.MeshBasicMaterial({color: 0x9900FF}));
        contactButton.position.set(3, 0, -1);  // Move down by 2 x buttonSpacing
        contactButton.rotation.y = rotationY;
        contactButton.userData = { type: 'image', src: 'images/ContactInfo.png' };
        scene.add(contactButton);

        const resumeButton = new THREE.Mesh(new THREE.BoxGeometry(buttonSize, buttonSize, 0.2), new THREE.MeshBasicMaterial({color: 0x6AA84F}));
        resumeButton.position.set(4.5, 0, -1);  // Move down by 3 x buttonSpacing
        resumeButton.rotation.y = rotationY;
        resumeButton.userData = { type: 'image', src: 'images/Conner_Curtis_Resume.png' };
        scene.add(resumeButton);

        // To handle touch interactivity
        session.addEventListener('selectstart', () => {
            const raycaster = new THREE.Raycaster();
            raycaster.setFromCamera(new THREE.Vector2(), camera);
            const intersects = raycaster.intersectObjects([githubButton, linkedinButton, contactButton, resumeButton]);

            if (intersects.length > 0) {
                const object = intersects[0].object;
                if (object.userData.type === 'link') {
                    window.location.href = object.userData.url;
                } else if (object.userData.type === 'image') {
                    if (object === contactButton)
                    {
                        imageView.position.set(3, 2, -1);
                    }
                    if (object === resumeButton)
                    {
                        imageView.position.set(4.5, 2, -1);
                    }
                    textureLoader.load(object.userData.src, (texture) => {
                        imageView.material.map = texture;
                        imageView.material.opacity = 1;  // Make the imageView visible
                        imageView.material.needsUpdate = true;
                    });
                }
            }

            // Optional: Check if the image viewer itself was touched to hide it
            const imageIntersects = raycaster.intersectObject(imageView);
            if (imageIntersects.length > 0) {
                imageView.material.opacity = 0;
                imageView.material.needsUpdate = true;
            }
        });


        // Create a render loop that allows us to draw on the AR view.
        const onXRFrame = (time, frame) => {
            // Queue up the next draw request.
            session.requestAnimationFrame(onXRFrame);

            // Bind the graphics framebuffer to the baseLayer's framebuffer
            gl.bindFramebuffer(gl.FRAMEBUFFER, session.renderState.baseLayer.framebuffer)

            // Retrieve the pose of the device.
            // XRFrame.getViewerPose can return null while the session attempts to establish tracking.
            const pose = frame.getViewerPose(referenceSpace);
            if (pose) {
                // In mobile AR, we only have one view.
                const view = pose.views[0];

                const viewport = session.renderState.baseLayer.getViewport(view);
                renderer.setSize(viewport.width, viewport.height)

                // Use the view's transform matrix and projection matrix to configure the THREE.camera.
                camera.matrix.fromArray(view.transform.matrix)
                camera.projectionMatrix.fromArray(view.projectionMatrix);
                camera.updateMatrixWorld(true);



                // Render the scene with THREE.WebGLRenderer.
                renderer.render(scene, camera)
            }
        }
        session.requestAnimationFrame(onXRFrame);
    }
</script>
</body>
</html>
